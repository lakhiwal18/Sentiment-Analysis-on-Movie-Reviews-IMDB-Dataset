# -*- coding: utf-8 -*-
"""IMDB__decision_tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yRnOpfDGEqLo_RWZRTyEg62oXowGnk66
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import string
from nltk.corpus import stopwords

from google.colab import drive
drive.mount('/content/drive')

path='/content/drive/MyDrive/IMDB Dataset.csv'
data=pd.read_csv(path)

data.shape

data_IMDB =data.iloc[:15000]
# data_IMDB  = data.iloc[:10000]
data_IMDB ['review'][1]
data_IMDB .shape

data_IMDB['sentiment'].value_counts()

"""## Preprocessing of data"""

data_IMDB.isnull().sum()

data_IMDB.shape

# Droping the duplicates in the dataset
data_IMDB.drop_duplicates(inplace=True)

import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords
import string


# Pipeline for the text preprocessiong
def preprocessing_text(text):
    

    # Tokenization of the text
    tokens = nltk.word_tokenize(text)


    # Removing stopwords
    stopwords_list = stopwords.words('english')
    filtered_tokens = [token for token in tokens if token not in stopwords_list]
    
    # making tokens in the lowercase format
    lowercase_tokens = [token.lower() for token in filtered_tokens]
    
    # Removing  punctuation 
    translator = str.maketrans('', '', string.punctuation)
    no_punct_tokens = [token.translate(translator) for token in lowercase_tokens]
    
    # deleting empty tokens from the dataset
    final_tokens = [token for token in no_punct_tokens if token]
    
    # Joining the tokens in a string
    preprocessed_text = ' '.join(final_tokens)
    
    return preprocessed_text

data_IMDB.duplicated().sum()

data_IMDB['review']= data_IMDB['review'].apply(preprocessing_text)

X= data_IMDB['review']
print(X.shape)
y = data_IMDB['sentiment']

print(y)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
y = encoder.fit_transform(y)
print(y)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)

X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.25,random_state=0)

print(X_train.head())

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()

tfidf_x_train = vectorizer.fit_transform(X_train).toarray()
tfidf_x_test=   vectorizer.transform(X_test).toarray()
tfidf_x_val=    vectorizer.transform(X_val).toarray()

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(tfidf_x_train,y_train)

y_pred_val = dtc.predict(tfidf_x_val)
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# accuracy score
accuracy = accuracy_score(y_val, y_pred_val)
print('Accuracy:', accuracy)

# precision score
precision = precision_score(y_val, y_pred_val)
print('Precision:', precision)

# recall score
recall = recall_score(y_val, y_pred_val)
print('Recall:', recall)

# F1 score
f1 = f1_score(y_val, y_pred_val)
print('F1 score:', f1)

# confusion matrix
confusion_mat = confusion_matrix(y_val, y_pred_val)
print('Confusion matrix:\n', confusion_mat)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
y_pred_test = dtc.predict(tfidf_x_test)

# accuracy score
accuracy = accuracy_score(y_test, y_pred_test)
print('Accuracy:', accuracy)

# precision score
precision = precision_score(y_test, y_pred_test)
print('Precision:', precision)

# recall score
recall = recall_score(y_test, y_pred_test)
print('Recall:', recall)

# F1 score
f1 = f1_score(y_test, y_pred_test)
print('F1 score:', f1)

# confusion matrix
confusion_mat = confusion_matrix(y_test, y_pred_test)
print('Confusion matrix:\n', confusion_mat)

# Compute training and validation loss for Naive Bayes
dtc_train_loss = 1 - accuracy_score(y_train, dtc.predict(tfidf_x_train))
dtc_val_loss = 1 - accuracy_score(y_val, dtc.predict(tfidf_x_val))
print("Naive Bayes training loss: {:.2f}".format(dtc_train_loss))
print("Naive Bayes validation loss: {:.2f}".format(dtc_val_loss))